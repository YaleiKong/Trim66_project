{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce53b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed447150",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 done, 736401 rows written.\n",
      "Chunk 2 done, 749019 rows written.\n",
      "Chunk 3 done, 734436 rows written.\n",
      "Chunk 4 done, 722452 rows written.\n",
      "Chunk 5 done, 804302 rows written.\n",
      "Chunk 6 done, 1000000 rows written.\n",
      "Chunk 7 done, 1000000 rows written.\n",
      "Chunk 8 done, 1000000 rows written.\n",
      "Chunk 9 done, 915736 rows written.\n",
      "Chunk 10 done, 728511 rows written.\n",
      "Chunk 11 done, 717015 rows written.\n",
      "Chunk 12 done, 815664 rows written.\n",
      "Chunk 13 done, 961144 rows written.\n",
      "Chunk 14 done, 728769 rows written.\n",
      "Chunk 15 done, 737443 rows written.\n",
      "Chunk 16 done, 749899 rows written.\n",
      "Chunk 17 done, 981188 rows written.\n",
      "Chunk 18 done, 734256 rows written.\n",
      "Chunk 19 done, 719060 rows written.\n",
      "Chunk 20 done, 838152 rows written.\n",
      "Chunk 21 done, 828259 rows written.\n",
      "Chunk 22 done, 724731 rows written.\n",
      "Chunk 23 done, 724284 rows written.\n",
      "Chunk 24 done, 920389 rows written.\n",
      "Chunk 25 done, 715945 rows written.\n",
      "Chunk 26 done, 729130 rows written.\n",
      "Chunk 27 done, 864878 rows written.\n",
      "Chunk 28 done, 724190 rows written.\n",
      "Chunk 29 done, 718657 rows written.\n",
      "Chunk 30 done, 828817 rows written.\n",
      "Chunk 31 done, 735090 rows written.\n",
      "Chunk 32 done, 736885 rows written.\n",
      "Chunk 33 done, 764781 rows written.\n",
      "Chunk 34 done, 703588 rows written.\n",
      "Chunk 35 done, 779528 rows written.\n",
      "Chunk 36 done, 727763 rows written.\n",
      "Chunk 37 done, 730818 rows written.\n",
      "Chunk 38 done, 729668 rows written.\n",
      "Chunk 39 done, 1000000 rows written.\n",
      "Chunk 40 done, 915779 rows written.\n",
      "Chunk 41 done, 754741 rows written.\n",
      "Chunk 42 done, 740890 rows written.\n",
      "Chunk 43 done, 727850 rows written.\n",
      "Chunk 44 done, 706310 rows written.\n",
      "Chunk 45 done, 996559 rows written.\n",
      "Chunk 46 done, 997197 rows written.\n",
      "Chunk 47 done, 1000000 rows written.\n",
      "Chunk 48 done, 803936 rows written.\n",
      "Chunk 49 done, 751633 rows written.\n",
      "Chunk 50 done, 724012 rows written.\n",
      "Chunk 51 done, 733696 rows written.\n",
      "Chunk 52 done, 1000000 rows written.\n",
      "Chunk 53 done, 996480 rows written.\n",
      "Chunk 54 done, 891461 rows written.\n",
      "Chunk 55 done, 739302 rows written.\n",
      "Chunk 56 done, 724713 rows written.\n",
      "Chunk 57 done, 726874 rows written.\n",
      "Chunk 58 done, 949113 rows written.\n",
      "Chunk 59 done, 996864 rows written.\n",
      "Chunk 60 done, 926994 rows written.\n",
      "Chunk 61 done, 745271 rows written.\n",
      "Chunk 62 done, 714338 rows written.\n",
      "Chunk 63 done, 726937 rows written.\n",
      "Chunk 64 done, 938557 rows written.\n",
      "Chunk 65 done, 997060 rows written.\n",
      "Chunk 66 done, 887812 rows written.\n",
      "Chunk 67 done, 734951 rows written.\n",
      "Chunk 68 done, 725634 rows written.\n",
      "Chunk 69 done, 711970 rows written.\n",
      "Chunk 70 done, 995675 rows written.\n",
      "Chunk 71 done, 993523 rows written.\n",
      "Chunk 72 done, 743456 rows written.\n",
      "Chunk 73 done, 713669 rows written.\n",
      "Chunk 74 done, 711779 rows written.\n",
      "Chunk 75 done, 968783 rows written.\n",
      "Chunk 76 done, 954822 rows written.\n",
      "Chunk 77 done, 732583 rows written.\n",
      "Chunk 78 done, 719463 rows written.\n",
      "Chunk 79 done, 776512 rows written.\n",
      "Chunk 80 done, 1000000 rows written.\n",
      "Chunk 81 done, 816978 rows written.\n",
      "Chunk 82 done, 741028 rows written.\n",
      "Chunk 83 done, 715765 rows written.\n",
      "Chunk 84 done, 737930 rows written.\n",
      "Chunk 85 done, 743029 rows written.\n",
      "Chunk 86 done, 70675 rows written.\n",
      "✅ 所有有效数据已写入 gzip 文件： ../files/Het_1.parsed.mapq30.sorted.deduped.valid.pairs.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_1/Het_1.parsed.mapq30.sorted.deduped.pairs.gz\"\n",
    "output_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_1/Het_1.parsed.mapq30.sorted.deduped.valid.pairs.gz\"\n",
    "chunksize = 1000000\n",
    "\n",
    "excluded_chroms = set([\n",
    "    'GL456210.1', 'GL456211.1', 'GL456212.1', 'GL456213.1', 'GL456216.1', 'GL456219.1', 'GL456221.1',\n",
    "    'GL456233.1', 'GL456239.1', 'GL456350.1', 'GL456354.1', 'GL456359.1', 'GL456360.1', 'GL456366.1',\n",
    "    'GL456367.1', 'GL456368.1', 'GL456370.1', 'GL456372.1', 'GL456378.1', 'GL456379.1', 'GL456381.1',\n",
    "    'GL456382.1', 'GL456383.1', 'GL456385.1', 'GL456387.1', 'GL456389.1', 'GL456390.1', 'GL456392.1',\n",
    "    'GL456393.1', 'GL456394.1', 'GL456396.1', 'JH584292.1', 'JH584293.1', 'JH584294.1', 'JH584295.1',\n",
    "    'JH584296.1', 'JH584297.1', 'JH584298.1', 'JH584299.1', 'JH584300.1', 'JH584301.1', 'JH584302.1',\n",
    "    'JH584303.1', 'JH584304.1'\n",
    "])\n",
    "\n",
    "colnames = ['readID', 'chrom1', 'pos1', 'chrom2', 'pos2', 'strand1', 'strand2', 'pair_type']\n",
    "\n",
    "# 标记是否首次写入\n",
    "first_write = True\n",
    "\n",
    "reader = pd.read_csv(input_file, sep='\\t', comment='#', header=None,\n",
    "                     names=colnames, chunksize=chunksize, compression='gzip')\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    mask_valid_chroms = ~chunk['chrom1'].isin(excluded_chroms) & ~chunk['chrom2'].isin(excluded_chroms)\n",
    "    same_chr = chunk['chrom1'] == chunk['chrom2']\n",
    "    short_range = abs(chunk['pos1'] - chunk['pos2']) < 1000\n",
    "    mask_long_cis = ~(same_chr & short_range)\n",
    "    filtered_chunk = chunk[mask_valid_chroms & mask_long_cis]\n",
    "\n",
    "    # 第一次写入 header=False；后续 append mode\n",
    "    filtered_chunk.to_csv(output_file, sep='\\t', index=False, header=False,\n",
    "                          mode='wt' if first_write else 'at', compression='gzip')\n",
    "    first_write = False\n",
    "\n",
    "    print(f\"Chunk {i+1} done, {len(filtered_chunk)} rows written.\")\n",
    "\n",
    "print(\"✅ 所有有效数据已写入 gzip 文件：\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8d9f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 done, 728136 rows written.\n",
      "Chunk 2 done, 739229 rows written.\n",
      "Chunk 3 done, 728391 rows written.\n",
      "Chunk 4 done, 712350 rows written.\n",
      "Chunk 5 done, 768301 rows written.\n",
      "Chunk 6 done, 1000000 rows written.\n",
      "Chunk 7 done, 1000000 rows written.\n",
      "Chunk 8 done, 1000000 rows written.\n",
      "Chunk 9 done, 863257 rows written.\n",
      "Chunk 10 done, 715694 rows written.\n",
      "Chunk 11 done, 710399 rows written.\n",
      "Chunk 12 done, 843793 rows written.\n",
      "Chunk 13 done, 906375 rows written.\n",
      "Chunk 14 done, 722640 rows written.\n",
      "Chunk 15 done, 727513 rows written.\n",
      "Chunk 16 done, 771863 rows written.\n",
      "Chunk 17 done, 936550 rows written.\n",
      "Chunk 18 done, 722185 rows written.\n",
      "Chunk 19 done, 708901 rows written.\n",
      "Chunk 20 done, 863941 rows written.\n",
      "Chunk 21 done, 783633 rows written.\n",
      "Chunk 22 done, 719134 rows written.\n",
      "Chunk 23 done, 712953 rows written.\n",
      "Chunk 24 done, 901955 rows written.\n",
      "Chunk 25 done, 712411 rows written.\n",
      "Chunk 26 done, 716835 rows written.\n",
      "Chunk 27 done, 851582 rows written.\n",
      "Chunk 28 done, 715984 rows written.\n",
      "Chunk 29 done, 709713 rows written.\n",
      "Chunk 30 done, 819465 rows written.\n",
      "Chunk 31 done, 726052 rows written.\n",
      "Chunk 32 done, 731948 rows written.\n",
      "Chunk 33 done, 753554 rows written.\n",
      "Chunk 34 done, 696831 rows written.\n",
      "Chunk 35 done, 766455 rows written.\n",
      "Chunk 36 done, 720826 rows written.\n",
      "Chunk 37 done, 724860 rows written.\n",
      "Chunk 38 done, 691873 rows written.\n",
      "Chunk 39 done, 992833 rows written.\n",
      "Chunk 40 done, 911594 rows written.\n",
      "Chunk 41 done, 747448 rows written.\n",
      "Chunk 42 done, 730142 rows written.\n",
      "Chunk 43 done, 720306 rows written.\n",
      "Chunk 44 done, 704822 rows written.\n",
      "Chunk 45 done, 961254 rows written.\n",
      "Chunk 46 done, 997383 rows written.\n",
      "Chunk 47 done, 1000000 rows written.\n",
      "Chunk 48 done, 766600 rows written.\n",
      "Chunk 49 done, 740175 rows written.\n",
      "Chunk 50 done, 714866 rows written.\n",
      "Chunk 51 done, 738370 rows written.\n",
      "Chunk 52 done, 996714 rows written.\n",
      "Chunk 53 done, 1000000 rows written.\n",
      "Chunk 54 done, 823056 rows written.\n",
      "Chunk 55 done, 731614 rows written.\n",
      "Chunk 56 done, 703228 rows written.\n",
      "Chunk 57 done, 725365 rows written.\n",
      "Chunk 58 done, 993915 rows written.\n",
      "Chunk 59 done, 996969 rows written.\n",
      "Chunk 60 done, 835061 rows written.\n",
      "Chunk 61 done, 732398 rows written.\n",
      "Chunk 62 done, 706784 rows written.\n",
      "Chunk 63 done, 724585 rows written.\n",
      "Chunk 64 done, 997167 rows written.\n",
      "Chunk 65 done, 1000000 rows written.\n",
      "Chunk 66 done, 776764 rows written.\n",
      "Chunk 67 done, 718732 rows written.\n",
      "Chunk 68 done, 714076 rows written.\n",
      "Chunk 69 done, 797901 rows written.\n",
      "Chunk 70 done, 995899 rows written.\n",
      "Chunk 71 done, 880203 rows written.\n",
      "Chunk 72 done, 715796 rows written.\n",
      "Chunk 73 done, 705644 rows written.\n",
      "Chunk 74 done, 779684 rows written.\n",
      "Chunk 75 done, 997083 rows written.\n",
      "Chunk 76 done, 823409 rows written.\n",
      "Chunk 77 done, 718470 rows written.\n",
      "Chunk 78 done, 706642 rows written.\n",
      "Chunk 79 done, 890053 rows written.\n",
      "Chunk 80 done, 951489 rows written.\n",
      "Chunk 81 done, 725004 rows written.\n",
      "Chunk 82 done, 729720 rows written.\n",
      "Chunk 83 done, 713290 rows written.\n",
      "Chunk 84 done, 725635 rows written.\n",
      "Chunk 85 done, 522494 rows written.\n",
      "✅ 所有有效数据已写入 gzip 文件： /lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_2/Het_2.parsed.mapq30.sorted.deduped.valid.pairs.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_2/Het_2.parsed.mapq30.sorted.deduped.pairs.gz\"\n",
    "output_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_2/Het_2.parsed.mapq30.sorted.deduped.valid.pairs.gz\"\n",
    "chunksize = 1000000\n",
    "\n",
    "excluded_chroms = set([\n",
    "    'GL456210.1', 'GL456211.1', 'GL456212.1', 'GL456213.1', 'GL456216.1', 'GL456219.1', 'GL456221.1',\n",
    "    'GL456233.1', 'GL456239.1', 'GL456350.1', 'GL456354.1', 'GL456359.1', 'GL456360.1', 'GL456366.1',\n",
    "    'GL456367.1', 'GL456368.1', 'GL456370.1', 'GL456372.1', 'GL456378.1', 'GL456379.1', 'GL456381.1',\n",
    "    'GL456382.1', 'GL456383.1', 'GL456385.1', 'GL456387.1', 'GL456389.1', 'GL456390.1', 'GL456392.1',\n",
    "    'GL456393.1', 'GL456394.1', 'GL456396.1', 'JH584292.1', 'JH584293.1', 'JH584294.1', 'JH584295.1',\n",
    "    'JH584296.1', 'JH584297.1', 'JH584298.1', 'JH584299.1', 'JH584300.1', 'JH584301.1', 'JH584302.1',\n",
    "    'JH584303.1', 'JH584304.1'\n",
    "])\n",
    "\n",
    "colnames = ['readID', 'chrom1', 'pos1', 'chrom2', 'pos2', 'strand1', 'strand2', 'pair_type']\n",
    "\n",
    "# 标记是否首次写入\n",
    "first_write = True\n",
    "\n",
    "reader = pd.read_csv(input_file, sep='\\t', comment='#', header=None,\n",
    "                     names=colnames, chunksize=chunksize, compression='gzip')\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    mask_valid_chroms = ~chunk['chrom1'].isin(excluded_chroms) & ~chunk['chrom2'].isin(excluded_chroms)\n",
    "    same_chr = chunk['chrom1'] == chunk['chrom2']\n",
    "    short_range = abs(chunk['pos1'] - chunk['pos2']) < 1000\n",
    "    mask_long_cis = ~(same_chr & short_range)\n",
    "    filtered_chunk = chunk[mask_valid_chroms & mask_long_cis]\n",
    "\n",
    "    # 第一次写入 header=False；后续 append mode\n",
    "    filtered_chunk.to_csv(output_file, sep='\\t', index=False, header=False,\n",
    "                          mode='wt' if first_write else 'at', compression='gzip')\n",
    "    first_write = False\n",
    "\n",
    "    print(f\"Chunk {i+1} done, {len(filtered_chunk)} rows written.\")\n",
    "\n",
    "print(\"✅ 所有有效数据已写入 gzip 文件：\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac520d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 done, 685310 rows written.\n",
      "Chunk 2 done, 698430 rows written.\n",
      "Chunk 3 done, 686909 rows written.\n",
      "Chunk 4 done, 671044 rows written.\n",
      "Chunk 5 done, 701940 rows written.\n",
      "Chunk 6 done, 1000000 rows written.\n",
      "Chunk 7 done, 1000000 rows written.\n",
      "Chunk 8 done, 1000000 rows written.\n",
      "Chunk 9 done, 830069 rows written.\n",
      "Chunk 10 done, 671651 rows written.\n",
      "Chunk 11 done, 668783 rows written.\n",
      "Chunk 12 done, 808063 rows written.\n",
      "Chunk 13 done, 896177 rows written.\n",
      "Chunk 14 done, 681153 rows written.\n",
      "Chunk 15 done, 690452 rows written.\n",
      "Chunk 16 done, 708470 rows written.\n",
      "Chunk 17 done, 945038 rows written.\n",
      "Chunk 18 done, 681388 rows written.\n",
      "Chunk 19 done, 665046 rows written.\n",
      "Chunk 20 done, 803204 rows written.\n",
      "Chunk 21 done, 778267 rows written.\n",
      "Chunk 22 done, 679039 rows written.\n",
      "Chunk 23 done, 674432 rows written.\n",
      "Chunk 24 done, 877759 rows written.\n",
      "Chunk 25 done, 665922 rows written.\n",
      "Chunk 26 done, 683870 rows written.\n",
      "Chunk 27 done, 809645 rows written.\n",
      "Chunk 28 done, 685248 rows written.\n",
      "Chunk 29 done, 667818 rows written.\n",
      "Chunk 30 done, 782282 rows written.\n",
      "Chunk 31 done, 686749 rows written.\n",
      "Chunk 32 done, 647062 rows written.\n",
      "Chunk 33 done, 758168 rows written.\n",
      "Chunk 34 done, 664117 rows written.\n",
      "Chunk 35 done, 715282 rows written.\n",
      "Chunk 36 done, 686213 rows written.\n",
      "Chunk 37 done, 672922 rows written.\n",
      "Chunk 38 done, 675399 rows written.\n",
      "Chunk 39 done, 836782 rows written.\n",
      "Chunk 40 done, 1000000 rows written.\n",
      "Chunk 41 done, 709416 rows written.\n",
      "Chunk 42 done, 704860 rows written.\n",
      "Chunk 43 done, 674523 rows written.\n",
      "Chunk 44 done, 672997 rows written.\n",
      "Chunk 45 done, 801048 rows written.\n",
      "Chunk 46 done, 1000000 rows written.\n",
      "Chunk 47 done, 997564 rows written.\n",
      "Chunk 48 done, 831679 rows written.\n",
      "Chunk 49 done, 702838 rows written.\n",
      "Chunk 50 done, 680428 rows written.\n",
      "Chunk 51 done, 673325 rows written.\n",
      "Chunk 52 done, 888331 rows written.\n",
      "Chunk 53 done, 996763 rows written.\n",
      "Chunk 54 done, 896516 rows written.\n",
      "Chunk 55 done, 690010 rows written.\n",
      "Chunk 56 done, 677708 rows written.\n",
      "Chunk 57 done, 683379 rows written.\n",
      "Chunk 58 done, 846867 rows written.\n",
      "Chunk 59 done, 997125 rows written.\n",
      "Chunk 60 done, 917811 rows written.\n",
      "Chunk 61 done, 697516 rows written.\n",
      "Chunk 62 done, 667034 rows written.\n",
      "Chunk 63 done, 679478 rows written.\n",
      "Chunk 64 done, 859175 rows written.\n",
      "Chunk 65 done, 997368 rows written.\n",
      "Chunk 66 done, 854347 rows written.\n",
      "Chunk 67 done, 686538 rows written.\n",
      "Chunk 68 done, 678185 rows written.\n",
      "Chunk 69 done, 642906 rows written.\n",
      "Chunk 70 done, 967842 rows written.\n",
      "Chunk 71 done, 974957 rows written.\n",
      "Chunk 72 done, 690599 rows written.\n",
      "Chunk 73 done, 662815 rows written.\n",
      "Chunk 74 done, 667719 rows written.\n",
      "Chunk 75 done, 913393 rows written.\n",
      "Chunk 76 done, 938024 rows written.\n",
      "Chunk 77 done, 682999 rows written.\n",
      "Chunk 78 done, 668624 rows written.\n",
      "Chunk 79 done, 700698 rows written.\n",
      "Chunk 80 done, 996916 rows written.\n",
      "Chunk 81 done, 775468 rows written.\n",
      "Chunk 82 done, 696819 rows written.\n",
      "Chunk 83 done, 667504 rows written.\n",
      "Chunk 84 done, 684247 rows written.\n",
      "Chunk 85 done, 688297 rows written.\n",
      "Chunk 86 done, 220185 rows written.\n",
      "✅ 所有有效数据已写入 gzip 文件： /lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_3/Het_3.parsed.mapq30.sorted.deduped.valid.pairs.gz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_3/Het_3.parsed.mapq30.sorted.deduped.pairs.gz\"\n",
    "output_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Het_3/Het_3.parsed.mapq30.sorted.deduped.valid.pairs.gz\"\n",
    "chunksize = 1000000\n",
    "\n",
    "excluded_chroms = set([\n",
    "    'GL456210.1', 'GL456211.1', 'GL456212.1', 'GL456213.1', 'GL456216.1', 'GL456219.1', 'GL456221.1',\n",
    "    'GL456233.1', 'GL456239.1', 'GL456350.1', 'GL456354.1', 'GL456359.1', 'GL456360.1', 'GL456366.1',\n",
    "    'GL456367.1', 'GL456368.1', 'GL456370.1', 'GL456372.1', 'GL456378.1', 'GL456379.1', 'GL456381.1',\n",
    "    'GL456382.1', 'GL456383.1', 'GL456385.1', 'GL456387.1', 'GL456389.1', 'GL456390.1', 'GL456392.1',\n",
    "    'GL456393.1', 'GL456394.1', 'GL456396.1', 'JH584292.1', 'JH584293.1', 'JH584294.1', 'JH584295.1',\n",
    "    'JH584296.1', 'JH584297.1', 'JH584298.1', 'JH584299.1', 'JH584300.1', 'JH584301.1', 'JH584302.1',\n",
    "    'JH584303.1', 'JH584304.1'\n",
    "])\n",
    "\n",
    "colnames = ['readID', 'chrom1', 'pos1', 'chrom2', 'pos2', 'strand1', 'strand2', 'pair_type']\n",
    "\n",
    "# 标记是否首次写入\n",
    "first_write = True\n",
    "\n",
    "reader = pd.read_csv(input_file, sep='\\t', comment='#', header=None,\n",
    "                     names=colnames, chunksize=chunksize, compression='gzip')\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    mask_valid_chroms = ~chunk['chrom1'].isin(excluded_chroms) & ~chunk['chrom2'].isin(excluded_chroms)\n",
    "    same_chr = chunk['chrom1'] == chunk['chrom2']\n",
    "    short_range = abs(chunk['pos1'] - chunk['pos2']) < 1000\n",
    "    mask_long_cis = ~(same_chr & short_range)\n",
    "    filtered_chunk = chunk[mask_valid_chroms & mask_long_cis]\n",
    "\n",
    "    # 第一次写入 header=False；后续 append mode\n",
    "    filtered_chunk.to_csv(output_file, sep='\\t', index=False, header=False,\n",
    "                          mode='wt' if first_write else 'at', compression='gzip')\n",
    "    first_write = False\n",
    "\n",
    "    print(f\"Chunk {i+1} done, {len(filtered_chunk)} rows written.\")\n",
    "\n",
    "print(\"✅ 所有有效数据已写入 gzip 文件：\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e720e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_1/Homo_1.parsed.mapq30.sorted.deduped.pairs.gz\"\n",
    "output_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_1/Homo_1.parsed.mapq30.sorted.deduped.valid.pairs.gz\"\n",
    "chunksize = 1000000\n",
    "\n",
    "excluded_chroms = set([\n",
    "    'GL456210.1', 'GL456211.1', 'GL456212.1', 'GL456213.1', 'GL456216.1', 'GL456219.1', 'GL456221.1',\n",
    "    'GL456233.1', 'GL456239.1', 'GL456350.1', 'GL456354.1', 'GL456359.1', 'GL456360.1', 'GL456366.1',\n",
    "    'GL456367.1', 'GL456368.1', 'GL456370.1', 'GL456372.1', 'GL456378.1', 'GL456379.1', 'GL456381.1',\n",
    "    'GL456382.1', 'GL456383.1', 'GL456385.1', 'GL456387.1', 'GL456389.1', 'GL456390.1', 'GL456392.1',\n",
    "    'GL456393.1', 'GL456394.1', 'GL456396.1', 'JH584292.1', 'JH584293.1', 'JH584294.1', 'JH584295.1',\n",
    "    'JH584296.1', 'JH584297.1', 'JH584298.1', 'JH584299.1', 'JH584300.1', 'JH584301.1', 'JH584302.1',\n",
    "    'JH584303.1', 'JH584304.1'\n",
    "])\n",
    "\n",
    "colnames = ['readID', 'chrom1', 'pos1', 'chrom2', 'pos2', 'strand1', 'strand2', 'pair_type']\n",
    "\n",
    "# 标记是否首次写入\n",
    "first_write = True\n",
    "\n",
    "reader = pd.read_csv(input_file, sep='\\t', comment='#', header=None,\n",
    "                     names=colnames, chunksize=chunksize, compression='gzip')\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    mask_valid_chroms = ~chunk['chrom1'].isin(excluded_chroms) & ~chunk['chrom2'].isin(excluded_chroms)\n",
    "    same_chr = chunk['chrom1'] == chunk['chrom2']\n",
    "    short_range = abs(chunk['pos1'] - chunk['pos2']) < 1000\n",
    "    mask_long_cis = ~(same_chr & short_range)\n",
    "    filtered_chunk = chunk[mask_valid_chroms & mask_long_cis]\n",
    "\n",
    "    # 第一次写入 header=False；后续 append mode\n",
    "    filtered_chunk.to_csv(output_file, sep='\\t', index=False, header=False,\n",
    "                          mode='wt' if first_write else 'at', compression='gzip')\n",
    "    first_write = False\n",
    "\n",
    "    print(f\"Chunk {i+1} done, {len(filtered_chunk)} rows written.\")\n",
    "\n",
    "print(\"✅ 所有有效数据已写入 gzip 文件：\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chunk 1 done, 712947 rows written.\n",
    "Chunk 2 done, 716899 rows written.\n",
    "Chunk 3 done, 712402 rows written.\n",
    "Chunk 4 done, 692602 rows written.\n",
    "Chunk 5 done, 673188 rows written.\n",
    "Chunk 6 done, 1000000 rows written.\n",
    "Chunk 7 done, 1000000 rows written.\n",
    "Chunk 8 done, 1000000 rows written.\n",
    "Chunk 9 done, 760891 rows written.\n",
    "Chunk 10 done, 690611 rows written.\n",
    "Chunk 11 done, 684869 rows written.\n",
    "Chunk 12 done, 884905 rows written.\n",
    "Chunk 13 done, 811345 rows written.\n",
    "Chunk 14 done, 697928 rows written.\n",
    "Chunk 15 done, 690528 rows written.\n",
    "Chunk 16 done, 825204 rows written.\n",
    "Chunk 17 done, 836239 rows written.\n",
    "Chunk 18 done, 696792 rows written.\n",
    "Chunk 19 done, 685184 rows written.\n",
    "Chunk 20 done, 890805 rows written.\n",
    "Chunk 21 done, 708112 rows written.\n",
    "Chunk 22 done, 689334 rows written.\n",
    "Chunk 23 done, 743049 rows written.\n",
    "Chunk 24 done, 813100 rows written.\n",
    "Chunk 25 done, 685351 rows written.\n",
    "Chunk 26 done, 684757 rows written.\n",
    "Chunk 27 done, 832142 rows written.\n",
    "Chunk 28 done, 696751 rows written.\n",
    "Chunk 29 done, 672670 rows written.\n",
    "Chunk 30 done, 801849 rows written.\n",
    "Chunk 31 done, 701101 rows written.\n",
    "Chunk 32 done, 730164 rows written.\n",
    "Chunk 33 done, 706941 rows written.\n",
    "Chunk 34 done, 675822 rows written.\n",
    "Chunk 35 done, 743903 rows written.\n",
    "Chunk 36 done, 694385 rows written.\n",
    "Chunk 37 done, 697483 rows written.\n",
    "Chunk 38 done, 668790 rows written.\n",
    "Chunk 39 done, 957251 rows written.\n",
    "Chunk 40 done, 877911 rows written.\n",
    "Chunk 41 done, 724526 rows written.\n",
    "Chunk 42 done, 711800 rows written.\n",
    "Chunk 43 done, 698146 rows written.\n",
    "Chunk 44 done, 677187 rows written.\n",
    "Chunk 45 done, 933900 rows written.\n",
    "Chunk 46 done, 997548 rows written.\n",
    "Chunk 47 done, 935683 rows written.\n",
    "Chunk 48 done, 722532 rows written.\n",
    "Chunk 49 done, 710474 rows written.\n",
    "Chunk 50 done, 691027 rows written.\n",
    "Chunk 51 done, 762325 rows written.\n",
    "Chunk 52 done, 996773 rows written.\n",
    "Chunk 53 done, 967105 rows written.\n",
    "Chunk 54 done, 716233 rows written.\n",
    "Chunk 55 done, 705299 rows written.\n",
    "Chunk 56 done, 684736 rows written.\n",
    "Chunk 57 done, 774956 rows written.\n",
    "Chunk 58 done, 997402 rows written.\n",
    "Chunk 59 done, 938398 rows written.\n",
    "Chunk 60 done, 716245 rows written.\n",
    "Chunk 61 done, 691603 rows written.\n",
    "Chunk 62 done, 686204 rows written.\n",
    "Chunk 63 done, 844539 rows written.\n",
    "Chunk 64 done, 997607 rows written.\n",
    "Chunk 65 done, 825315 rows written.\n",
    "Chunk 66 done, 708233 rows written.\n",
    "Chunk 67 done, 698073 rows written.\n",
    "Chunk 68 done, 656408 rows written.\n",
    "Chunk 69 done, 991811 rows written.\n",
    "Chunk 70 done, 911045 rows written.\n",
    "Chunk 71 done, 697558 rows written.\n",
    "Chunk 72 done, 687865 rows written.\n",
    "Chunk 73 done, 674999 rows written.\n",
    "Chunk 74 done, 997520 rows written.\n",
    "Chunk 75 done, 829336 rows written.\n",
    "Chunk 76 done, 701348 rows written.\n",
    "Chunk 77 done, 683480 rows written.\n",
    "Chunk 78 done, 818240 rows written.\n",
    "Chunk 79 done, 962108 rows written.\n",
    "Chunk 80 done, 705436 rows written.\n",
    "Chunk 81 done, 705864 rows written.\n",
    "Chunk 82 done, 664724 rows written.\n",
    "Chunk 83 done, 707975 rows written.\n",
    "Chunk 84 done, 593091 rows written.\n",
    "✅ 所有有效数据已写入 gzip 文件： /lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_1/Homo_1.parsed.mapq30.sorted.deduped.valid.pairs.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_2/Homo_2.parsed.mapq30.sorted.deduped.pairs.gz\"\n",
    "output_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_2/Homo_2.parsed.mapq30.sorted.deduped.valid.pairs.gz\"\n",
    "chunksize = 1000000\n",
    "\n",
    "excluded_chroms = set([\n",
    "    'GL456210.1', 'GL456211.1', 'GL456212.1', 'GL456213.1', 'GL456216.1', 'GL456219.1', 'GL456221.1',\n",
    "    'GL456233.1', 'GL456239.1', 'GL456350.1', 'GL456354.1', 'GL456359.1', 'GL456360.1', 'GL456366.1',\n",
    "    'GL456367.1', 'GL456368.1', 'GL456370.1', 'GL456372.1', 'GL456378.1', 'GL456379.1', 'GL456381.1',\n",
    "    'GL456382.1', 'GL456383.1', 'GL456385.1', 'GL456387.1', 'GL456389.1', 'GL456390.1', 'GL456392.1',\n",
    "    'GL456393.1', 'GL456394.1', 'GL456396.1', 'JH584292.1', 'JH584293.1', 'JH584294.1', 'JH584295.1',\n",
    "    'JH584296.1', 'JH584297.1', 'JH584298.1', 'JH584299.1', 'JH584300.1', 'JH584301.1', 'JH584302.1',\n",
    "    'JH584303.1', 'JH584304.1'\n",
    "])\n",
    "\n",
    "colnames = ['readID', 'chrom1', 'pos1', 'chrom2', 'pos2', 'strand1', 'strand2', 'pair_type']\n",
    "\n",
    "# 标记是否首次写入\n",
    "first_write = True\n",
    "\n",
    "reader = pd.read_csv(input_file, sep='\\t', comment='#', header=None,\n",
    "                     names=colnames, chunksize=chunksize, compression='gzip')\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    mask_valid_chroms = ~chunk['chrom1'].isin(excluded_chroms) & ~chunk['chrom2'].isin(excluded_chroms)\n",
    "    same_chr = chunk['chrom1'] == chunk['chrom2']\n",
    "    short_range = abs(chunk['pos1'] - chunk['pos2']) < 1000\n",
    "    mask_long_cis = ~(same_chr & short_range)\n",
    "    filtered_chunk = chunk[mask_valid_chroms & mask_long_cis]\n",
    "\n",
    "    # 第一次写入 header=False；后续 append mode\n",
    "    filtered_chunk.to_csv(output_file, sep='\\t', index=False, header=False,\n",
    "                          mode='wt' if first_write else 'at', compression='gzip')\n",
    "    first_write = False\n",
    "\n",
    "    print(f\"Chunk {i+1} done, {len(filtered_chunk)} rows written.\")\n",
    "\n",
    "print(\"✅ 所有有效数据已写入 gzip 文件：\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chunk 1 done, 762511 rows written.\n",
    "Chunk 2 done, 769646 rows written.\n",
    "Chunk 3 done, 762932 rows written.\n",
    "Chunk 4 done, 750810 rows written.\n",
    "Chunk 5 done, 809823 rows written.\n",
    "Chunk 6 done, 1000000 rows written.\n",
    "Chunk 7 done, 1000000 rows written.\n",
    "Chunk 8 done, 931264 rows written.\n",
    "Chunk 9 done, 759340 rows written.\n",
    "Chunk 10 done, 745622 rows written.\n",
    "Chunk 11 done, 813976 rows written.\n",
    "Chunk 12 done, 917294 rows written.\n",
    "Chunk 13 done, 759242 rows written.\n",
    "Chunk 14 done, 753757 rows written.\n",
    "Chunk 15 done, 820120 rows written.\n",
    "Chunk 16 done, 890415 rows written.\n",
    "Chunk 17 done, 754552 rows written.\n",
    "Chunk 18 done, 746630 rows written.\n",
    "Chunk 19 done, 902100 rows written.\n",
    "Chunk 20 done, 763454 rows written.\n",
    "Chunk 21 done, 746219 rows written.\n",
    "Chunk 22 done, 855361 rows written.\n",
    "Chunk 23 done, 777351 rows written.\n",
    "Chunk 24 done, 752552 rows written.\n",
    "Chunk 25 done, 806086 rows written.\n",
    "Chunk 26 done, 794672 rows written.\n",
    "Chunk 27 done, 747237 rows written.\n",
    "Chunk 28 done, 821649 rows written.\n",
    "Chunk 29 done, 761608 rows written.\n",
    "Chunk 30 done, 729950 rows written.\n",
    "Chunk 31 done, 808864 rows written.\n",
    "Chunk 32 done, 739093 rows written.\n",
    "Chunk 33 done, 784277 rows written.\n",
    "Chunk 34 done, 755106 rows written.\n",
    "Chunk 35 done, 753606 rows written.\n",
    "Chunk 36 done, 730989 rows written.\n",
    "Chunk 37 done, 984992 rows written.\n",
    "Chunk 38 done, 863497 rows written.\n",
    "Chunk 39 done, 778567 rows written.\n",
    "Chunk 40 done, 762729 rows written.\n",
    "Chunk 41 done, 750956 rows written.\n",
    "Chunk 42 done, 787878 rows written.\n",
    "Chunk 43 done, 1000000 rows written.\n",
    "Chunk 44 done, 997435 rows written.\n",
    "Chunk 45 done, 824103 rows written.\n",
    "Chunk 46 done, 772975 rows written.\n",
    "Chunk 47 done, 750892 rows written.\n",
    "Chunk 48 done, 756652 rows written.\n",
    "Chunk 49 done, 996948 rows written.\n",
    "Chunk 50 done, 991591 rows written.\n",
    "Chunk 51 done, 767866 rows written.\n",
    "Chunk 52 done, 760801 rows written.\n",
    "Chunk 53 done, 748017 rows written.\n",
    "Chunk 54 done, 850159 rows written.\n",
    "Chunk 55 done, 997407 rows written.\n",
    "Chunk 56 done, 893032 rows written.\n",
    "Chunk 57 done, 768158 rows written.\n",
    "Chunk 58 done, 742196 rows written.\n",
    "Chunk 59 done, 748458 rows written.\n",
    "Chunk 60 done, 980128 rows written.\n",
    "Chunk 61 done, 971312 rows written.\n",
    "Chunk 62 done, 766583 rows written.\n",
    "Chunk 63 done, 757426 rows written.\n",
    "Chunk 64 done, 739173 rows written.\n",
    "Chunk 65 done, 905031 rows written.\n",
    "Chunk 66 done, 976031 rows written.\n",
    "Chunk 67 done, 760842 rows written.\n",
    "Chunk 68 done, 747394 rows written.\n",
    "Chunk 69 done, 737481 rows written.\n",
    "Chunk 70 done, 983894 rows written.\n",
    "Chunk 71 done, 856137 rows written.\n",
    "Chunk 72 done, 755693 rows written.\n",
    "Chunk 73 done, 742940 rows written.\n",
    "Chunk 74 done, 899230 rows written.\n",
    "Chunk 75 done, 905696 rows written.\n",
    "Chunk 76 done, 765369 rows written.\n",
    "Chunk 77 done, 750969 rows written.\n",
    "Chunk 78 done, 752906 rows written.\n",
    "Chunk 79 done, 753683 rows written.\n",
    "Chunk 80 done, 242613 rows written.\n",
    "✅ 所有有效数据已写入 gzip 文件： /lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_2/Homo_2.parsed.mapq30.sorted.deduped.valid.pairs.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de17b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_3/Homo_3.parsed.mapq30.sorted.deduped.pairs.gz\"\n",
    "output_file = \"/lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_3/Homo_3.parsed.mapq30.sorted.deduped.valid.pairs.gz\"\n",
    "chunksize = 1000000\n",
    "\n",
    "excluded_chroms = set([\n",
    "    'GL456210.1', 'GL456211.1', 'GL456212.1', 'GL456213.1', 'GL456216.1', 'GL456219.1', 'GL456221.1',\n",
    "    'GL456233.1', 'GL456239.1', 'GL456350.1', 'GL456354.1', 'GL456359.1', 'GL456360.1', 'GL456366.1',\n",
    "    'GL456367.1', 'GL456368.1', 'GL456370.1', 'GL456372.1', 'GL456378.1', 'GL456379.1', 'GL456381.1',\n",
    "    'GL456382.1', 'GL456383.1', 'GL456385.1', 'GL456387.1', 'GL456389.1', 'GL456390.1', 'GL456392.1',\n",
    "    'GL456393.1', 'GL456394.1', 'GL456396.1', 'JH584292.1', 'JH584293.1', 'JH584294.1', 'JH584295.1',\n",
    "    'JH584296.1', 'JH584297.1', 'JH584298.1', 'JH584299.1', 'JH584300.1', 'JH584301.1', 'JH584302.1',\n",
    "    'JH584303.1', 'JH584304.1'\n",
    "])\n",
    "\n",
    "colnames = ['readID', 'chrom1', 'pos1', 'chrom2', 'pos2', 'strand1', 'strand2', 'pair_type']\n",
    "\n",
    "# 标记是否首次写入\n",
    "first_write = True\n",
    "\n",
    "reader = pd.read_csv(input_file, sep='\\t', comment='#', header=None,\n",
    "                     names=colnames, chunksize=chunksize, compression='gzip')\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    mask_valid_chroms = ~chunk['chrom1'].isin(excluded_chroms) & ~chunk['chrom2'].isin(excluded_chroms)\n",
    "    same_chr = chunk['chrom1'] == chunk['chrom2']\n",
    "    short_range = abs(chunk['pos1'] - chunk['pos2']) < 1000\n",
    "    mask_long_cis = ~(same_chr & short_range)\n",
    "    filtered_chunk = chunk[mask_valid_chroms & mask_long_cis]\n",
    "\n",
    "    # 第一次写入 header=False；后续 append mode\n",
    "    filtered_chunk.to_csv(output_file, sep='\\t', index=False, header=False,\n",
    "                          mode='wt' if first_write else 'at', compression='gzip')\n",
    "    first_write = False\n",
    "\n",
    "    print(f\"Chunk {i+1} done, {len(filtered_chunk)} rows written.\")\n",
    "\n",
    "print(\"✅ 所有有效数据已写入 gzip 文件：\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf012b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chunk 1 done, 762831 rows written.\n",
    "Chunk 2 done, 770782 rows written.\n",
    "Chunk 3 done, 766930 rows written.\n",
    "Chunk 4 done, 752766 rows written.\n",
    "Chunk 5 done, 748799 rows written.\n",
    "Chunk 6 done, 1000000 rows written.\n",
    "Chunk 7 done, 1000000 rows written.\n",
    "Chunk 8 done, 1000000 rows written.\n",
    "Chunk 9 done, 795787 rows written.\n",
    "Chunk 10 done, 745619 rows written.\n",
    "Chunk 11 done, 747184 rows written.\n",
    "Chunk 12 done, 925166 rows written.\n",
    "Chunk 13 done, 832305 rows written.\n",
    "Chunk 14 done, 757463 rows written.\n",
    "Chunk 15 done, 754044 rows written.\n",
    "Chunk 16 done, 863158 rows written.\n",
    "Chunk 17 done, 863189 rows written.\n",
    "Chunk 18 done, 753508 rows written.\n",
    "Chunk 19 done, 748292 rows written.\n",
    "Chunk 20 done, 912279 rows written.\n",
    "Chunk 21 done, 763910 rows written.\n",
    "Chunk 22 done, 752170 rows written.\n",
    "Chunk 23 done, 798694 rows written.\n",
    "Chunk 24 done, 844862 rows written.\n",
    "Chunk 25 done, 745211 rows written.\n",
    "Chunk 26 done, 744726 rows written.\n",
    "Chunk 27 done, 863498 rows written.\n",
    "Chunk 28 done, 756093 rows written.\n",
    "Chunk 29 done, 738539 rows written.\n",
    "Chunk 30 done, 838103 rows written.\n",
    "Chunk 31 done, 756203 rows written.\n",
    "Chunk 32 done, 792425 rows written.\n",
    "Chunk 33 done, 750388 rows written.\n",
    "Chunk 34 done, 739063 rows written.\n",
    "Chunk 35 done, 795467 rows written.\n",
    "Chunk 36 done, 751672 rows written.\n",
    "Chunk 37 done, 757387 rows written.\n",
    "Chunk 38 done, 732435 rows written.\n",
    "Chunk 39 done, 976329 rows written.\n",
    "Chunk 40 done, 887934 rows written.\n",
    "Chunk 41 done, 777701 rows written.\n",
    "Chunk 42 done, 768442 rows written.\n",
    "Chunk 43 done, 757478 rows written.\n",
    "Chunk 44 done, 741059 rows written.\n",
    "Chunk 45 done, 954748 rows written.\n",
    "Chunk 46 done, 997424 rows written.\n",
    "Chunk 47 done, 938387 rows written.\n",
    "Chunk 48 done, 774059 rows written.\n",
    "Chunk 49 done, 763370 rows written.\n",
    "Chunk 50 done, 752601 rows written.\n",
    "Chunk 51 done, 835535 rows written.\n",
    "Chunk 52 done, 996724 rows written.\n",
    "Chunk 53 done, 945376 rows written.\n",
    "Chunk 54 done, 766409 rows written.\n",
    "Chunk 55 done, 760445 rows written.\n",
    "Chunk 56 done, 752360 rows written.\n",
    "Chunk 57 done, 849634 rows written.\n",
    "Chunk 58 done, 997335 rows written.\n",
    "Chunk 59 done, 921526 rows written.\n",
    "Chunk 60 done, 772578 rows written.\n",
    "Chunk 61 done, 746164 rows written.\n",
    "Chunk 62 done, 753308 rows written.\n",
    "Chunk 63 done, 896259 rows written.\n",
    "Chunk 64 done, 997412 rows written.\n",
    "Chunk 65 done, 840691 rows written.\n",
    "Chunk 66 done, 759731 rows written.\n",
    "Chunk 67 done, 758963 rows written.\n",
    "Chunk 68 done, 742075 rows written.\n",
    "Chunk 69 done, 995939 rows written.\n",
    "Chunk 70 done, 914822 rows written.\n",
    "Chunk 71 done, 755674 rows written.\n",
    "Chunk 72 done, 746695 rows written.\n",
    "Chunk 73 done, 745989 rows written.\n",
    "Chunk 74 done, 997291 rows written.\n",
    "Chunk 75 done, 861330 rows written.\n",
    "Chunk 76 done, 758612 rows written.\n",
    "Chunk 77 done, 746441 rows written.\n",
    "Chunk 78 done, 850077 rows written.\n",
    "Chunk 79 done, 974041 rows written.\n",
    "Chunk 80 done, 760089 rows written.\n",
    "Chunk 81 done, 766732 rows written.\n",
    "Chunk 82 done, 737312 rows written.\n",
    "Chunk 83 done, 759379 rows written.\n",
    "Chunk 84 done, 643602 rows written.\n",
    "✅ 所有有效数据已写入 gzip 文件： /lustre/home/acct-medlqian/medlqian-loop3/data/Hi_C/20250520_Trim66_HiC_20250609_46G/output/Homo_3/Homo_3.parsed.mapq30.sorted.deduped.valid.pairs.gz\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooltools_env",
   "language": "python",
   "name": "cooltools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
